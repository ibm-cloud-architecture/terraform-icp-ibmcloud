##################################
### Deploy ICP to cluster
##################################
module "icpprovision" {
    source = "github.com/ibm-cloud-architecture/terraform-module-icp-deploy.git?ref=3.1.1"

    # Provide IP addresses for boot, master, mgmt, va, proxy and workers
    boot-node = "${ibm_is_instance.icp-boot.primary_network_interface.0.primary_ipv4_address}"
    bastion_host  = "${ibm_is_floating_ip.icp-boot-pub.address}"
    icp-host-groups = {
        master = ["${ibm_is_instance.icp-master.*.primary_network_interface.0.primary_ipv4_address}"]
        proxy = "${slice(concat(ibm_is_instance.icp-proxy.*.primary_network_interface.0.primary_ipv4_address,
                                ibm_is_instance.icp-master.*.primary_network_interface.0.primary_ipv4_address),
                         var.proxy["nodes"] > 0 ? 0 : length(ibm_is_instance.icp-proxy.*.primary_network_interface.0.primary_ipv4_address),
                         var.proxy["nodes"] > 0 ? length(ibm_is_instance.icp-proxy.*.primary_network_interface.0.primary_ipv4_address) :
                                                  length(ibm_is_instance.icp-proxy.*.primary_network_interface.0.primary_ipv4_address) +
                                                    length(ibm_is_instance.icp-master.*.primary_network_interface.0.primary_ipv4_address))}"

        worker = ["${ibm_is_instance.icp-worker.*.primary_network_interface.0.primary_ipv4_address}"]

        // make the master nodes managements nodes if we don't have any specified
        management = "${slice(concat(ibm_is_instance.icp-mgmt.*.primary_network_interface.0.primary_ipv4_address,
                                     ibm_is_instance.icp-master.*.primary_network_interface.0.primary_ipv4_address),
                              var.mgmt["nodes"] > 0 ? 0 : length(ibm_is_instance.icp-mgmt.*.primary_network_interface.0.primary_ipv4_address),
                              var.mgmt["nodes"] > 0 ? length(ibm_is_instance.icp-mgmt.*.primary_network_interface.0.primary_ipv4_address) :
                                                      length(ibm_is_instance.icp-mgmt.*.primary_network_interface.0.primary_ipv4_address) +
                                                        length(ibm_is_instance.icp-master.*.primary_network_interface.0.primary_ipv4_address))}"

        va = ["${ibm_is_instance.icp-va.*.primary_network_interface.0.primary_ipv4_address}"]
    }

    icp-inception = "${local.icp-version}"

    image_location = "${var.image_location}"
    image_location_user = "${var.image_location_user}"
    image_location_pass = "${var.image_location_password}"

    /* Workaround for terraform issue #10857
     When this is fixed, we can work this out automatically */
    cluster_size  = "${1 + var.master["nodes"] + var.worker["nodes"] + var.proxy["nodes"] + var.mgmt["nodes"] + var.va["nodes"]}"

    ###################################################################################################################################
    ## You can feed in arbitrary configuration items in the icp_configuration map.
    ## Available configuration items availble from https://www.ibm.com/support/knowledgecenter/SSBS6K_3.1.0/installing/config_yaml.html
    icp_configuration = {
      "network_cidr"                    = "${var.pod_network_cidr}"
      "service_cluster_ip_range"        = "${var.service_network_cidr}"
      "cluster_lb_address"              = "${ibm_is_lb.master.hostname}"
      "proxy_lb_address"                = "${ibm_is_lb.proxy.hostname}"
      "cluster_CA_domain"               = "${var.cluster_cname != "" ? "${var.cluster_cname}" : "${ibm_is_lb.master.hostname}"}"
      "cluster_name"                    = "${var.deployment}"
      "calico_ip_autodetection_method"  = "interface=eth0"

      # An admin password will be generated if not supplied in terraform.tfvars
      "default_admin_password"          = "${local.icppassword}"

      # This is the list of disabled management services
      "management_services"             = "${local.disabled_management_services}"

      "private_registry_enabled"        = "${local.registry_server != "" ? "true" : "false" }"
      "private_registry_server"         = "${local.registry_server}"
      "image_repo"                      = "${local.image_repo}" # Will either be our private repo or external repo
      "docker_username"                 = "${local.docker_username}" # Will either be username generated by us or supplied by user
      "docker_password"                 = "${local.docker_password}" # Will either be username generated by us or supplied by user
    }

    # We will let terraform generate a new ssh keypair
    # for boot master to communicate with worker and proxy nodes
    # during ICP deployment
    generate_key = true

    # SSH user and key for terraform to connect to newly created VMs
    # ssh_key is the private key corresponding to the public assumed to be included in the template
    ssh_user        = "icpdeploy"
    ssh_key_base64  = "${base64encode(tls_private_key.installkey.private_key_pem)}"
    ssh_agent       = false

    # a hack to wait for the listeners to come up before we start installing
    hooks = {
      "boot-preconfig" = [
        "echo ${ibm_is_lb_listener.master-8001.id} > /dev/null",
        "echo ${ibm_is_lb_listener.master-8443.id} > /dev/null",
        "echo ${ibm_is_lb_listener.master-8500.id} > /dev/null",
        "echo ${ibm_is_lb_listener.master-8600.id} > /dev/null",
        "echo ${ibm_is_lb_listener.master-9443.id} > /dev/null",
        "echo ${join(",", ibm_is_lb_pool_member.master-8001.*.id)} > /dev/null",
        "echo ${join(",", ibm_is_lb_pool_member.master-8443.*.id)} > /dev/null",
        "echo ${join(",", ibm_is_lb_pool_member.master-8500.*.id)} > /dev/null",
        "echo ${join(",", ibm_is_lb_pool_member.master-8600.*.id)} > /dev/null",
        "echo ${join(",", ibm_is_lb_pool_member.master-9443.*.id)} > /dev/null",
        "while [ ! -f /var/lib/cloud/instance/boot-finished ]; do sleep 1; done"
      ]
      # wait for cloud-init to finish on all the nodes before we continue
      "cluster-preconfig" = [
        "while [ ! -f /var/lib/cloud/instance/boot-finished ]; do sleep 1; done"
      ],
      "cluster-postconfig" = ["echo No hook"]
      "preinstall" = ["echo No hook"]
      "postinstall" = ["echo No hook"]
    }

    # Make sure to wait for image load to complete

    # hooks = {
    #   "boot-preconfig" = [
    #     "while [ ! -f /opt/ibm/.imageload_complete ]; do sleep 5; done"
    #   ]
    # }

}

output "icp_console_host" {
  value = "${ibm_is_lb.master.hostname}"
}

output "icp_proxy_host" {
  value = "${ibm_is_lb.proxy.hostname}"
}

output "icp_console_url" {
  value = "https://${ibm_is_lb.master.hostname}:8443"
}

output "icp_registry_url" {
  value = "${ibm_is_lb.master.hostname}:8500"
}

output "kubernetes_api_url" {
  value = "https://${ibm_is_lb.master.hostname}:8001"
}

output "icp_admin_username" {
  value = "admin"
}

output "icp_admin_password" {
  value = "${local.icppassword}"
}
